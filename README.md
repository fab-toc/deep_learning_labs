# Deep Learning Labs

## LAB 2

### Q1: Put the values of these gradients in your report.

Gradients of loss: $\nabla_{w} loss = -20$ and $\nabla_{b} loss = -10$

### Q2: What are the final values (i.e., after training) of the weight $w$ and bias $b$?

Final values after training: $w$ = 0.24 & $b$ = 0.8871

### Q3 & Q4

_Plots of loss over epochs & original/predicted data_

## LAB 3

### Q1: How many parameters are in the network?

As we have 3 linear layers (weight + biases) with: `input_size = 784, hidden_size = 10 and output_size = 10`, the number of parameters of the network is 8070.

### Q2

_Plots of loss over epochs_
Test accuracy of 68%

### Q3

Accuracy of 86%
Recommend to use ReLU

### Q4

_See plot of hidden size_
I would use a hidden size of 10 because we have a good accuracy with little width of hidden layers. A hidden size of 50 adds a lot of computing and does not add so much in accuracy.
